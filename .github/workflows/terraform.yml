# Add a short, numbered name for roadmap clarity
name: "02 - Terraform Infrastructure"
on:
  workflow_call:
    inputs:
      environment:
        description: 'Deployment environment'
        required: true
        type: string
      action:
        description: 'Terraform action to perform'
        required: false
        type: string
        default: 'plan'
    outputs:
      api_app_name:
        description: "The name of the API App Service"
        value: ${{ jobs.terraform.outputs.api_app_name }}
      react_app_name:
        description: "The name of the React App Service"
        value: ${{ jobs.terraform.outputs.react_app_name }}
      acr_registry_url:
        description: "The URL of the Azure Container Registry"
        value: ${{ jobs.terraform.outputs.acr_registry_url }}
    secrets:
      AZURE_CREDENTIALS:
        required: true
      AZURE_SUBSCRIPTION_ID:
        required: true
      SQL_ADMIN_USERNAME:
        required: true
      SQL_ADMIN_PASSWORD:
        required: true
      ARM_CLIENT_ID:
        required: true
      ARM_CLIENT_SECRET:
        required: true
      ARM_TENANT_ID:
        required: true


env:
  WORKING_DIRECTORY: './infra/terraform'

jobs:
  terraform:
    name: "Terraform ${{ inputs.action }}"
    runs-on: ubuntu-latest
    environment: ${{ inputs.environment }}
    timeout-minutes: 60

    outputs:
      api_app_name: ${{ steps.outputs.outputs.api_app_name }}
      react_app_name: ${{ steps.outputs.outputs.react_app_name }}
      acr_registry_url: ${{ steps.outputs.outputs.acr_registry_url }}

    permissions:
      contents: read
      id-token: write

    concurrency:
      group: terraform-${{ inputs.environment }}
      cancel-in-progress: false

    env:
      ARM_CLIENT_ID: ${{ secrets.ARM_CLIENT_ID }}
      ARM_CLIENT_SECRET: ${{ secrets.ARM_CLIENT_SECRET }}
      ARM_SUBSCRIPTION_ID: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
      ARM_TENANT_ID: ${{ secrets.ARM_TENANT_ID }}
      TF_VAR_environment: ${{ inputs.environment }}
      TF_VAR_subscription_id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
      TF_VAR_sql_admin_username: ${{ secrets.SQL_ADMIN_USERNAME }}
      TF_VAR_sql_admin_password: ${{ secrets.SQL_ADMIN_PASSWORD }}

    defaults:
      run:
        working-directory: ${{ env.WORKING_DIRECTORY }}

    steps:
      - name: Validate Inputs
        working-directory: .
        run: |
          # Validate action parameter
          if [[ ! "${{ inputs.action }}" =~ ^(plan|apply|destroy)$ ]]; then
            echo "‚ùå ERROR: Invalid action '${{ inputs.action }}'"
            echo "Valid actions are: plan, apply, destroy"
            exit 1
          fi

          echo "‚úÖ Input validation passed"
          echo "Action: ${{ inputs.action }}"
          echo "Environment: ${{ inputs.environment }}"

      - name: Checkout code
        uses: actions/checkout@v4.2.2

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3.1.2
        with:
          terraform_version: 1.9.0

      - name: Install Azure CLI
        run: |
          curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash

      - name: Login to Azure
        uses: azure/login@v2.3.0
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Terraform Format Check
        id: fmt
        run: terraform fmt -check -recursive || [ -n "$ACT" ]

      - name: Debug Environment Variables
        run: |
          echo "=== Terraform Environment Variables ==="
          echo "TF_VAR_environment: ${TF_VAR_environment}"
          echo "TF_VAR_subscription_id: ${TF_VAR_subscription_id:0:8}..."
          echo "TF_VAR_region: ${TF_VAR_region}"
          echo "TF_VAR_resource_group_name: ${TF_VAR_resource_group_name}"

          # Fail early if environment is empty
          if [ -z "${TF_VAR_environment}" ]; then
            echo "‚ùå ERROR: TF_VAR_environment is empty!"
            echo "When running with act, use: act workflow_dispatch --input environment=dev"
            exit 1
          fi

      - name: Terraform Init
        id: init
        run: terraform init

      - name: Read Configuration from terraform.tfvars
        id: read_config
        run: |
          echo ""
          echo "=== Reading Configuration from terraform.tfvars ==="
          echo ""

          # Extract resource_group_name from terraform.tfvars
          TF_VAR_resource_group_name=$(grep "^resource_group_name" terraform.tfvars | awk -F'=' '{print $2}' | tr -d ' "')
          echo "Resource Group (from tfvars): ${TF_VAR_resource_group_name}"

          # Export for use in constructing resource IDs
          echo "TF_VAR_resource_group_name=${TF_VAR_resource_group_name}" >> $GITHUB_ENV

          # Extract region from terraform.tfvars
          TF_VAR_region=$(grep "^region" terraform.tfvars | awk -F'=' '{print $2}' | tr -d ' "')
          echo "Region (from tfvars): ${TF_VAR_region}"

          # Export for use in Terraform
          echo "TF_VAR_region=${TF_VAR_region}" >> $GITHUB_ENV

          # Build RG_ID for later use
          RG_ID="/subscriptions/${TF_VAR_subscription_id}/resourceGroups/${TF_VAR_resource_group_name}"
          echo "Resource Group ID: ${RG_ID}"
          echo "RG_ID=${RG_ID}" >> $GITHUB_ENV

      - name: Detect and Import Existing Resources
        id: import
        run: |
          set +e  # Don't exit on error, we'll handle errors ourselves

          echo "=== Step 1: Reading CAE Configuration from terraform.tfvars ==="

          # Read CAE configuration from terraform.tfvars
          USE_SHARED_CAE=$(grep "^use_shared_container_environment" terraform.tfvars | awk -F'=' '{print $2}' | tr -d ' ')
          SHARED_CAE_NAME=$(grep "^shared_container_environment_name" terraform.tfvars | awk -F'=' '{print $2}' | tr -d ' "')
          CREATE_CAE=$(grep "^create_container_app_environment" terraform.tfvars | awk -F'=' '{print $2}' | tr -d ' ')

          echo "Configuration from terraform.tfvars:"
          echo "  use_shared_container_environment: ${USE_SHARED_CAE}"
          echo "  shared_container_environment_name: ${SHARED_CAE_NAME}"
          echo "  create_container_app_environment: ${CREATE_CAE}"

          # Determine expected CAE name based on configuration
          if [ "$USE_SHARED_CAE" = "true" ]; then
            # Shared mode: Use fixed name (NO environment substitution!)
            EXPECTED_CAE_NAME="${SHARED_CAE_NAME}"
            echo "Using shared mode with FIXED name: ${EXPECTED_CAE_NAME}"
            echo "  (This name is used across ALL environments: dev, staging, prod)"
          else
            # Template mode: Would resolve from template, but we'll just let Terraform handle it
            echo "Using template mode - Terraform will resolve the name"
            EXPECTED_CAE_NAME=""  # Don't try to guess
          fi

          # DON'T override create_container_app_environment - trust terraform.tfvars
          echo ""
          echo "Workflow will NOT override Terraform configuration variables"
          echo "All CAE settings will be managed by terraform.tfvars"

          echo ""
          echo "=== Step 2: Importing Existing Azure Resources ==="
          echo ""

          # Function to import a resource if it exists
          import_resource() {
            local tf_address="$1"
            local resource_id="$2"
            local resource_name="$3"

            # Check if already in state
            if terraform state list | grep -q "^${tf_address}\$"; then
              echo "  ‚úÖ Already in state: ${resource_name}"
              return 0
            fi

            # Try to import
            echo "  üì• Importing: ${resource_name}"
            local import_output
            if import_output=$(terraform import "${tf_address}" "${resource_id}" 2>&1); then
              echo "  ‚úÖ Imported successfully: ${resource_name}"
              return 0
            else
              # Check if error is because resource doesn't exist
              if echo "$import_output" | grep -q "Cannot import non-existent"; then
                echo "  ‚ÑπÔ∏è  Resource does not exist in Azure: ${resource_name}"
              elif echo "$import_output" | grep -q "Resource already managed"; then
                echo "  ‚úÖ Already managed: ${resource_name}"
              else
                echo "  ‚ö†Ô∏è  Import failed: ${resource_name}"
                echo "$import_output" | grep -i "error" | head -3
              fi
              return 1
            fi
          }

          echo "1. Resource Group"
          RG_ID="/subscriptions/${TF_VAR_subscription_id}/resourceGroups/${TF_VAR_resource_group_name}"
          import_resource "azurerm_resource_group.main" "${RG_ID}" "Resource Group"

          echo ""
          echo "2. Networking Resources"
          VNET_ID="${RG_ID}/providers/Microsoft.Network/virtualNetworks/consilient-vnet-${TF_VAR_environment}"
          SUBNET_ID="${VNET_ID}/subnets/consilient-subnet-${TF_VAR_environment}"
          import_resource "azurerm_virtual_network.main" "${VNET_ID}" "Virtual Network"
          import_resource "azurerm_subnet.main" "${SUBNET_ID}" "Subnet"

          echo ""
          echo "3. Container Registry"
          ACR_NAME=$(terraform output -raw acr_name 2>/dev/null || echo "consilientacr${TF_VAR_environment}$(echo -n "${TF_VAR_subscription_id}-${TF_VAR_resource_group_name}" | md5sum | cut -c1-6)")
          ACR_ID="${RG_ID}/providers/Microsoft.ContainerRegistry/registries/${ACR_NAME}"
          import_resource "azurerm_container_registry.main" "${ACR_ID}" "Container Registry"

          echo ""
          echo "4. SQL Server and Databases"
          SQL_SUFFIX=$(echo -n "${TF_VAR_subscription_id}-${TF_VAR_resource_group_name}" | md5sum | cut -c1-6)
          SQL_SERVER_NAME="consilient-sqlsrv-${TF_VAR_environment}-${SQL_SUFFIX}"
          SQL_SERVER_ID="${RG_ID}/providers/Microsoft.Sql/servers/${SQL_SERVER_NAME}"
          MAIN_DB_ID="${SQL_SERVER_ID}/databases/consilient_main_${TF_VAR_environment}"
          HANGFIRE_DB_ID="${SQL_SERVER_ID}/databases/consilient_hangfire_${TF_VAR_environment}"
          import_resource "azurerm_mssql_server.main" "${SQL_SERVER_ID}" "SQL Server"
          import_resource "module.main_db.azurerm_mssql_database.this" "${MAIN_DB_ID}" "Main Database"
          import_resource "module.hangfire_db.azurerm_mssql_database.this" "${HANGFIRE_DB_ID}" "Hangfire Database"

          echo ""
          echo "5. Storage Account and Container"
          STORAGE_NAME="consilientloki${TF_VAR_environment}${SQL_SUFFIX}"
          STORAGE_ID="${RG_ID}/providers/Microsoft.Storage/storageAccounts/${STORAGE_NAME}"
          STORAGE_CONTAINER_ID="${STORAGE_ID}/blobServices/default/containers/loki-data"
          PRIVATE_ENDPOINT_ID="${RG_ID}/providers/Microsoft.Network/privateEndpoints/consilient-pe-loki-storage-${TF_VAR_environment}"
          import_resource "azurerm_storage_account.loki" "${STORAGE_ID}" "Loki Storage Account"
          import_resource "azurerm_storage_container.loki" "${STORAGE_CONTAINER_ID}" "Loki Storage Container"
          import_resource "azurerm_private_endpoint.loki_storage" "${PRIVATE_ENDPOINT_ID}" "Loki Storage Private Endpoint"

          echo ""
          echo "6. Managed Identity"
          IDENTITY_ID="${RG_ID}/providers/Microsoft.ManagedIdentity/userAssignedIdentities/consilient-loki-identity-${TF_VAR_environment}"
          import_resource "azurerm_user_assigned_identity.loki" "${IDENTITY_ID}" "Loki Managed Identity"

          echo ""
          echo "7. Role Assignment (Loki -> Storage)"
          # Get the principal_id of the managed identity
          PRINCIPAL_ID=$(az identity show --ids "${IDENTITY_ID}" --query principalId -o tsv 2>/dev/null || echo "")
          if [ -n "$PRINCIPAL_ID" ]; then
            echo "  Found managed identity principal ID: ${PRINCIPAL_ID}"
            # List role assignments for the storage account and find the one with this principal
            ROLE_ASSIGNMENT_ID=$(az role assignment list --scope "${STORAGE_ID}" --query "[?principalId=='${PRINCIPAL_ID}'].id | [0]" -o tsv 2>/dev/null || echo "")
            if [ -n "$ROLE_ASSIGNMENT_ID" ]; then
              echo "  Found role assignment: ${ROLE_ASSIGNMENT_ID}"
              import_resource "azurerm_role_assignment.loki_blob" "${ROLE_ASSIGNMENT_ID}" "Loki Storage Blob Role Assignment"
            else
              echo "  ‚ÑπÔ∏è  No role assignment found for this managed identity on storage account"
            fi
          else
            echo "  ‚ÑπÔ∏è  Managed identity not found, skipping role assignment import"
          fi

          echo ""
          echo "8. Container App Environment"
          # Import CAE only if:
          # 1. We're NOT creating a new one (create_container_app_environment = false)
          # 2. We're in shared mode (use_shared_container_environment = true)
          # 3. The CAE name is known (from terraform.tfvars)
          # 4. The CAE is in the SAME resource group as other resources

          if [ "$CREATE_CAE" = "false" ] && [ "$USE_SHARED_CAE" = "true" ] && [ -n "$EXPECTED_CAE_NAME" ]; then
            echo "  Shared mode detected: Checking if CAE '${EXPECTED_CAE_NAME}' exists in resource group '${TF_VAR_resource_group_name}'"

            # Check if CAE exists in Azure in the SAME resource group
            CAE_EXISTS=$(az containerapp env show \
              --name "${EXPECTED_CAE_NAME}" \
              --resource-group "${TF_VAR_resource_group_name}" \
              --query "id" -o tsv 2>/dev/null || echo "")

            if [ -n "$CAE_EXISTS" ]; then
              echo "  CAE exists in same resource group - attempting import"
              CAE_ID="${RG_ID}/providers/Microsoft.App/managedEnvironments/${EXPECTED_CAE_NAME}"
              import_resource "azurerm_container_app_environment.shared[0]" "${CAE_ID}" "Container App Environment"
            else
              echo "  ‚ÑπÔ∏è  CAE '${EXPECTED_CAE_NAME}' not found in resource group '${TF_VAR_resource_group_name}'"
              echo "  ‚ÑπÔ∏è  Terraform will use data source to reference CAE from another resource group"
            fi
          elif [ "$CREATE_CAE" = "true" ]; then
            echo "  ‚ÑπÔ∏è  create_container_app_environment=true - Terraform will create a new CAE"
            echo "  ‚ÑπÔ∏è  Attempting to import in case it already exists..."

            # Try to determine CAE name (in template mode, Terraform resolves it)
            if [ "$USE_SHARED_CAE" = "true" ]; then
              CAE_NAME="${EXPECTED_CAE_NAME}"
            else
              # Template mode - resolve the template
              CAE_TEMPLATE=$(grep "^container_app_environment_name_template" terraform.tfvars | awk -F'=' '{print $2}' | tr -d ' "')
              CAE_NAME="${CAE_TEMPLATE/\{environment\}/${TF_VAR_environment}}"
            fi

            if [ -n "$CAE_NAME" ]; then
              CAE_ID="${RG_ID}/providers/Microsoft.App/managedEnvironments/${CAE_NAME}"
              import_resource "azurerm_container_app_environment.shared[0]" "${CAE_ID}" "Container App Environment"
            fi
          else
            echo "  ‚ÑπÔ∏è  CAE configuration doesn't require import (using existing CAE via data source or ID)"
          fi

          echo ""
          echo "9. Container App (Loki)"
          CONTAINER_APP_ID="${RG_ID}/providers/Microsoft.App/containerApps/consilient-loki-${TF_VAR_environment}"
          import_resource "azurerm_container_app.loki" "${CONTAINER_APP_ID}" "Loki Container App"

          echo ""
          echo "10. Grafana"
          GRAFANA_ID="${RG_ID}/providers/Microsoft.Dashboard/grafana/consilient-grafana-${TF_VAR_environment}"
          import_resource "azurerm_dashboard_grafana.main" "${GRAFANA_ID}" "Grafana Dashboard"

          echo ""
          echo "11. App Service Plans"
          ASP_REACT_ID="${RG_ID}/providers/Microsoft.Web/serverFarms/consilient-asp-react-${TF_VAR_environment}"
          ASP_API_ID="${RG_ID}/providers/Microsoft.Web/serverFarms/consilient-asp-api-${TF_VAR_environment}"
          import_resource "module.react_app.azurerm_service_plan.this" "${ASP_REACT_ID}" "React App Service Plan"
          import_resource "module.api_app.azurerm_service_plan.this" "${ASP_API_ID}" "API App Service Plan"

          echo ""
          echo "12. App Services"
          APP_REACT_ID="${RG_ID}/providers/Microsoft.Web/sites/consilient-react-${TF_VAR_environment}"
          APP_API_ID="${RG_ID}/providers/Microsoft.Web/sites/consilient-api-${TF_VAR_environment}"
          import_resource "module.react_app.azurerm_linux_web_app.this" "${APP_REACT_ID}" "React App Service"
          import_resource "module.api_app.azurerm_linux_web_app.this" "${APP_API_ID}" "API App Service"

          echo ""
          echo "=== Import Process Complete ==="
          echo ""
          echo "Configuration will be managed by terraform.tfvars"
          echo "No workflow overrides applied"

          exit 0  # Always succeed, imports are best-effort

      - name: Terraform Validate
        id: validate
        run: terraform validate

      - name: Terraform Plan
        id: plan
        if: inputs.action == 'plan'
        run: terraform plan

      - name: Terraform Apply
        if: inputs.action == 'apply'
        run: terraform apply -auto-approve

      - name: Capture Terraform Outputs
        id: outputs
        if: inputs.action == 'apply'
        run: |
          API_APP_NAME=$(terraform output -raw api_app_service_name 2>/dev/null || echo "")
          REACT_APP_NAME=$(terraform output -raw react_app_service_name 2>/dev/null || echo "")
          ACR_REGISTRY_URL=$(terraform output -raw acr_registry_url 2>/dev/null || echo "")

          echo "Captured Terraform Outputs:"
          echo "  API App Name: ${API_APP_NAME}"
          echo "  React App Name: ${REACT_APP_NAME}"
          echo "  ACR Registry URL: ${ACR_REGISTRY_URL}"

          echo "api_app_name=${API_APP_NAME}" >> $GITHUB_OUTPUT
          echo "react_app_name=${REACT_APP_NAME}" >> $GITHUB_OUTPUT
          echo "acr_registry_url=${ACR_REGISTRY_URL}" >> $GITHUB_OUTPUT

      - name: Terraform Destroy
        if: inputs.action == 'destroy'
        run: |
          if [ "${{ inputs.environment }}" == "prod" ]; then
            echo "‚ùå ERROR: Terraform destroy is not allowed in production environment!"
            echo "This is a safety measure to prevent accidental deletion of production resources."
            exit 1
          fi
          echo "‚úÖ Proceeding with destroy for environment: ${{ inputs.environment }}"
          terraform destroy -auto-approve
